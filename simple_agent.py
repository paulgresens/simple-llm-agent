import json
from typing import Final
from util import buildJudgementPrompt, loadClaimContextPairs, printAndLog
from local_agent import LLMAgent

agent = LLMAgent("tiiuae/Falcon3-10B-Instruct")

promptTemplate: Final= """ 
You are an accurate and reliable LLM-as-a-judge worker. Your tasks is to evaluate how well a claim from a generated answer is supported by the context in form of a couple of extracted sentences from a scientific paper. You can always assume that the information in the paper and thus in the context is factually correct.

Input Format:
You will recieve the following input:

- Claim: A single sentence generated by an arbitrary LLM.
- Context: A couple of sentences extracted from a scientific paper that may or may not justify the claim.

Evaluation Instructions:
Evaluate how well the claim is grounded in the context. For each of the provided criteria provided below, you should rate on a scale of 1-5 how well it is fullfilled. The scores have the following meaning:

- 1: Not Fullfilled - the criteria is not fullfilled
- 2: Partly Fullfilled - the criteria is partly fullfilled, but there are gaps, ambiguity or weaknesses
- 3: Fully Fullfilled - the criteria is fully satisfied

Use the following criterias for your rating:

1. Faithfulness:
   Faithfulness measures how well the claim made is based on the factual content of the context. This includes but not ends with:

   - Is the claim the logical consequence of the facts in the context?
   - Does the claim overgeneralize and thus produce unfounded conclusions, not based on the facts in the context?
   - Does the claim include interpretations of the information on the context, which lack further data to be correctly and justifiedly drawn?
   A good rating here means, that the claim made is based on the factual content, a bad rating means it is not.

2. Relevance:
   Relevance measures how well the topic in the context overlaps thematically with that in the generated claim and how precisely they address the same topics This includes:

   - Is the topic of the claim also part of the topic of the context?
   - Is each topic that is present in the claim also discussed in the context?
   - Does the context include extra information not needed for justifying the claim?
   A good rating here means, that the context is relevenant for the topic, a bad rating means it is not.

3. Consistency:
   Consistency measures if the claim is logically consistent in respect to the information in the claim. This includes:

   - Does the claim contradict the information in the context?
   - Does the claim contain conclusions or generalizations that are contradicted by the context?
   - Does the information in the context allow a conclusion that directly contradicts the information in the claim?
   A good rating here means, that the claim is logically consistent, a bad rating means it is not.

4. Support Coverage:
   Support Coverage measures wether the the context includes sufficient information to justify the claim. This includes:

   - Is each part of the claim justified by information in the context?
   A good rating here means, that the context includes sufficient information, a bad rating means it does not.

5. Paraphrase Robustness:
   Paraphrase Robustness measures wether the semantic meaning of the claim and the context are the same, even if they are worded differently. This includes:

   - Does the claim convey the same meaning as the context?
   - Does the claim include the same semantic entities as the context?
   - Can the claim be interpreted differently or does it meaning differ from that of the context due to different wording?
   A good rating here means, that the semantic meaning of the claim and the context are the same, a bad rating means they are not.
   

6. Ambiguity Level:
   Ambiguity Level measures wether the information in the context could be interpreted differently as done in the claim. This includes:
   - Is the information in the context ambiguous with respect to the claim?
   - Are there parts of the context that could be interpreted differently than done in the claim?
   A good rating here means, that the information in the context is unambiguous, a bad rating means it is not.

Output Format:
You will answer in form of the JSON Schema provided below.

{{
"faithfulness" : {{
   "rating": <1-5>,
   "justification": <justification>
   }},
"relevance" : {{
   "rating": <1-5>,
   "justification": <justification>
   }},
"consistency" :{{
   "rating": <1-5>,
   "justification": <justification>
   }},
"supportCoverage" :{{
   "rating": <1-5>,
   "justification": <justification>
   }},
"paraphraseRobustness" :{{
   "rating": <1-5>,
   "justification": <justification>
   }},
"ambiguityLevel": {{
   "rating": <1-5>,
   "justification": <justification>
   }},
"meanScore: <Average of the scores above>
}}

Dont add any extra information, explanation or thoughts. Strictly follow the JSON format. 
Each "<1-5>" bracket should be replaced with the score of the corresponding metric, also following valid JSON structure. 
For each rated criteria the "<justification>"  bracket should be replaced by an explanation on why you gave the ranking for that metric, up to 3 sentences.
The key "meanScore" should have the average value of all scores above.

Claim: "{claim}"
Context: "{context}"

"""
  
judgementData = loadClaimContextPairs()

for judgementDatapoint in judgementData:
   claimAndContext = judgementDatapoint.get("claimsAndContexts")
   printAndLog(judgementDatapoint.get("question"))

   for pair in claimAndContext:
      claim = pair.get("claim")
      context = pair.get("context")
   
      prompt = buildJudgementPrompt(promptTemplate,claim,context)
      llmJudgement = agent.generate(prompt)
      
      printAndLog("----------\n" + "claim: " + claim + "\n" + "context: " + context + "\n" + "llmJudgement: " + json.dumps(llmJudgement, ensure_ascii=False) + "\n" + "----------\n")
     

         


